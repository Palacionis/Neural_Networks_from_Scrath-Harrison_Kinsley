{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import nnfs # package by the book's author to generate random data\n",
    "from nnfs.datasets import spiral_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "nnfs.init()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full network with categorical cross entropy loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "# Dense layer\n",
    "\n",
    "class Layer_Dense():\n",
    "  \n",
    "  # layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "      self.weights = 0.01 * np.random.rand(n_inputs, n_neurons)\n",
    "      self.biases = np.zeros((1, n_neurons))\n",
    "      \n",
    "      \n",
    "      \n",
    "  # forward pass\n",
    "  def forward(self, inputs):\n",
    "    # calculate output values from inputs, weights and biases\n",
    "    self.output = np.dot(inputs, self.weights) + self.biases\n",
    "    \n",
    "    \n",
    "  \n",
    "# ReLU activation\n",
    "\n",
    "class Activation_Relu():\n",
    "   \n",
    "   # forward pass\n",
    "   def forward(self, inputs):\n",
    "     # calculate output values from inputs\n",
    "     self.output = np.maximum(0,inputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Softmax activation\n",
    "\n",
    "class Activation_Softmax():\n",
    "  \n",
    "  # forward pass\n",
    "  def forward(self, inputs):\n",
    "    \n",
    "    # get unnormalized probabilities\n",
    "    exp_values = np.exp(inputs - np.max(inputs, axis = 1, keepdims = True))\n",
    "    \n",
    "    # normalize probabilities\n",
    "    probabilities = exp_values / np.sum(exp_values, axis = 1, keepdims = True)\n",
    "    \n",
    "    self.output = probabilities\n",
    "    \n",
    "    \n",
    "\n",
    "# Common loss class\n",
    "\n",
    "class Loss():\n",
    "  \n",
    "  # calculates the data and regularization losses\n",
    "  # given model output and ground truth values\n",
    "  \n",
    "  def calculate(self, output, y):\n",
    "    # calculate sample loss\n",
    "    sample_losses = self.forward(output, y)\n",
    "    \n",
    "    # calculate mean loss\n",
    "    data_loss = np.mean(sample_losses)\n",
    "    \n",
    "    # return loss\n",
    "    return data_loss\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "# Cross-entropy loss\n",
    "\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "  \n",
    "  # forward pass\n",
    "  def forward(self, y_pred, y_true):\n",
    "    \n",
    "    # number of samples in a batch\n",
    "    samples = len(y_pred)\n",
    "    \n",
    "    # clip data to prevent division by 0\n",
    "    # clip both sides to not drag the mean towards any value\n",
    "    y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    \n",
    "    \n",
    "    # probabilites for target values\n",
    "    # only if categorical labels\n",
    "    \n",
    "    if len(y_true.shape) == 1:\n",
    "      correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "      \n",
    "    # mask values - only for one hot encoded labels\n",
    "    elif len(y_true.shape) == 2:\n",
    "      correct_confidences = np.sum(y_pred_clipped * y_true, axis = 1)\n",
    "    \n",
    "    \n",
    "    # Losses\n",
    "    negative_log_likelihoods = -np.log(correct_confidences)\n",
    "    return negative_log_likelihoods"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "# create dataset\n",
    "X, y = spiral_data(samples = 100, classes = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "source": [
    "# create dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# create ReLU activation which will be used with Dense layer\n",
    "activation1 = Activation_Relu()\n",
    "\n",
    "# create second dense layer with 3 input features from the previous layer and 3 output values\n",
    "dense2 = Layer_Dense(3,3)\n",
    "\n",
    "# create softmax activation which will be used with dense layer\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "# create a loss function\n",
    "loss_function = Loss_CategoricalCrossentropy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "dense1.weights.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 286
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "source": [
    "# perform the first pass of input data to the dense layer\n",
    "dense1.forward(X)\n",
    "print(dense1.output[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [8.0659374e-05 4.3710388e-05 6.5012209e-05]\n",
      " [1.5923499e-04 6.9124777e-05 1.0470775e-04]\n",
      " [2.3033096e-04 1.9152602e-04 2.7749798e-04]\n",
      " [1.9318146e-04 3.1980115e-04 4.5189835e-04]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# perform pass through the first activation function which takes the inputs from above - the layer before\n",
    "activation1.forward(dense1.output)\n",
    "print(activation1.output[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [2.6297315e-05 9.2926544e-05 5.1812236e-05]\n",
      " [0.0000000e+00 1.4744070e-04 0.0000000e+00]\n",
      " [2.3272418e-04 6.6075481e-05 3.0338956e-04]\n",
      " [0.0000000e+00 3.4931320e-04 0.0000000e+00]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# perfrom the second pass to the dense layer which input is the output from the activation function\n",
    "dense2.forward(activation1.output)\n",
    "print(dense2.output[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [1.0993491e-06 6.8928142e-07 4.6805695e-07]\n",
      " [1.1044792e-06 7.8488006e-07 1.6948626e-07]\n",
      " [3.4528434e-06 1.4912927e-06 2.3913783e-06]\n",
      " [2.6167072e-06 1.8595201e-06 4.0154302e-07]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# perform second activation function which takes inputs from the second dense layer\n",
    "activation2.forward(dense2.output)\n",
    "print(activation2.output[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333343 0.3333333  0.33333325]\n",
      " [0.33333346 0.33333334 0.33333316]\n",
      " [0.33333367 0.33333302 0.33333334]\n",
      " [0.33333364 0.3333334  0.33333293]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# perfrom a forward pass through loss function it takes the output of a second dense layer and returns loss\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "print(f'Loss: {loss}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 1.0986117124557495\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('Kursams': conda)"
  },
  "interpreter": {
   "hash": "2a893ff8458ba932f92e4e064d7c215f78239c4614ca04d610e727159f096c4f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}